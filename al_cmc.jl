### A Pluto.jl notebook ###
# v0.20.11

using Markdown
using InteractiveUtils

# This Pluto notebook uses @bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of @bind gives bound variables a default value (instead of an error).
macro bind(def, element)
    #! format: off
    return quote
        local iv = try Base.loaded_modules[Base.PkgId(Base.UUID("6e696c72-6542-2067-7265-42206c756150"), "AbstractPlutoDingetjes")].Bonds.initial_value catch; b -> missing; end
        local el = $(esc(element))
        global $(esc(def)) = Core.applicable(Base.get, el) ? Base.get(el) : iv(el)
        el
    end
    #! format: on
end

# â•”â•â•¡ cd47d8d0-5513-11f0-02cf-23409fc28fbf
begin
	import Pkg; Pkg.activate("cmc")
	using CairoMakie, DataFrames, Turing, MakieThemes, Colors, CSV, StatsBase, KernelDensity, Cubature, Test, PlutoUI, Logging, ProgressLogging, Printf
end

# â•”â•â•¡ 1e324846-70da-494c-bb88-8668a0f0e526
n_chains = Threads.nthreads() # using four threads

# â•”â•â•¡ 0801bc21-de7c-4470-ae89-8725d90812e9
begin
	# modifying the plot scheme
	# see here for other themes
	#  https://makieorg.github.io/MakieThemes.jl/dev/themes/ggthemr/
	local my_theme = :flat
	
	set_theme!(ggthemr(my_theme))
	update_theme!(
		fontsize=20, linewidth=4, 
		Axis=(bottomspinevisible=false, leftspinevisible=false, titlefont=:regular)
	)
	
	colors = parse.(Colorant, MakieThemes.GGThemr.ColorTheme[my_theme][:swatch])
end

# â•”â•â•¡ 4cb87445-d372-4957-9cdb-4cd4bcc397de
TableOfContents()

# â•”â•â•¡ 5a1768a0-865a-46ba-b70f-0194664d9d21
md"# read data"

# â•”â•â•¡ d506f9e7-0d4d-40eb-a938-e1465c836222
datafiles = [
	"H2O-C10E8", "H2O-C14E6", "H2O-CTAB-bulk",	"H2O-SDS-bulk",
	"H2O-C12E5", "H2O-C16E8", "H2O-OTG", "H2O-Tween20"
]

# â•”â•â•¡ 5da8817c-3460-4c04-b408-aff71e4576d4
md"
ğŸ”¨ subsample the data? check here. ğŸ‘‡

$(@bind subsample_the_data CheckBox(default=false))"

# â•”â•â•¡ 17d43d3c-ad92-4447-adc1-dbd23001c45e
md"â“ wut experiment?

$(@bind i_expt Select(1:length(datafiles), default=3))"

# â•”â•â•¡ 8511592a-9059-43a7-b14c-941b66641cb0
expt = datafiles[i_expt]

# â•”â•â•¡ 49de609d-4cc3-46d6-9141-5de0395088fb
begin
	function read_data(i::Int)
		data = CSV.read("data/" * datafiles[i] * ".csv", DataFrame)
		
		rename!(data, "concentration_mol/m^3" => "[S] (mol/mÂ³)")
		rename!(data, "surften_N/m" => "Î³ (N/m)")
		select!(data, ["[S] (mol/mÂ³)", "Î³ (N/m)"])

		@warn "assuming solvent is pure water."
		Î³â‚€ = 72.8 / 1000.0 # N/m
		pushfirst!(data, Dict("[S] (mol/mÂ³)" => 0.0, "Î³ (N/m)" => Î³â‚€))
		
		return data
	end

	data = read_data(i_expt)
	if subsample_the_data
		data = data[[1, 5, 18, end], :] # always include 1
	end
end

# â•”â•â•¡ 842d16b1-26e3-4cd2-81ac-83ed6cd3b6b3
md"surface tension of pure solvent (water)."

# â•”â•â•¡ 533a51d0-3b42-42e0-b8db-1ab7c672f3df
Î³â‚€ = data[1, "Î³ (N/m)"]

# â•”â•â•¡ 874cc30e-0d7d-4a82-a523-c0caa9da4a59
md"# surface tension vs surfactant concentration model"

# â•”â•â•¡ b686a78a-fba7-41f5-b30f-621e3416ae96
function Î³_model(c, Î³â‚€, a, K, câ˜…)
	if c < câ˜…
		return Î³â‚€ - a * log(1 + K * c)
	else
		return Î³â‚€ - a * log(1 + K * câ˜…)
	end
end

# â•”â•â•¡ ca288f74-bc34-457f-8caa-ab1627f5c46f
md"# Bayesian inference

## set up sampler
"

# â•”â•â•¡ c40e781e-bd35-4541-9eb3-f943df41587d
md"ğŸ” search space"

# â•”â•â•¡ 67d23697-2d05-46f2-80e4-75c85c369f80
c_max = maximum(read_data(i_expt)[:, "[S] (mol/mÂ³)"]) * 1.1

# â•”â•â•¡ 9b865570-b175-4fcb-a835-b8d6278c86ac
md"ğŸ“ measurement error"

# â•”â•â•¡ 17ab88fc-8d65-42a8-94a7-3ac643638ef7
Ïƒ = 0.001 # (N/m) 

# â•”â•â•¡ bcd013f5-3211-4ca4-ac1d-fae758199e75
@model function cmc_model(data::DataFrame)
	# begin with pure solvent so Î³â‚€ doesn't need inferred
	@assert data[1, "[S] (mol/mÂ³)"] == 0.0
	Î³â‚€ = data[1, "Î³ (N/m)"]
		
	#=
	prior distributions
	=#
	# Ïƒ ~ Uniform(0.0, 0.01)
	a ~ Uniform(0.0, 0.25)
	K ~ Uniform(0.0, 20.0)
	câ˜… ~ Uniform(0.0, c_max)

	#=
	show data
	=#
	for i = 1:nrow(data)
		# surfactant concentration
		cáµ¢ = data[i, "[S] (mol/mÂ³)"]
		
		# predicted surface tension
		Î³_pred = Î³_model(cáµ¢, Î³â‚€, a, K, câ˜…)
		
		data[i, "Î³ (N/m)"] ~ Normal(Î³_pred, Ïƒ)
	end
	
	return nothing
end

# â•”â•â•¡ 9d2f66ee-03aa-42d9-ae9d-6ee14f1f1f63
model = cmc_model(data)

# â•”â•â•¡ f0b122c9-4d43-405b-a28e-ead0c79772cb
md"## sample chain"

# â•”â•â•¡ ea27c7f7-0073-4d0b-a171-7b404af1d0d6
n_MC_samples = 2500

# â•”â•â•¡ 948a0fe4-e8ec-47e5-92a7-a66be020f0df
@time chain = sample(model, NUTS(), MCMCThreads(), n_MC_samples, n_chains)

# â•”â•â•¡ a4f779ba-9410-4e67-840f-7114561f23b4
params = chain.name_map.parameters

# â•”â•â•¡ 37dc8c68-2270-4226-b209-f3fab65b3b13
md"converge diagnostics"

# â•”â•â•¡ 52080b61-1e8d-4343-b79c-b3b39861e2c8
gelmandiag(chain)

# â•”â•â•¡ bfa76e5b-e2c3-449b-8de0-cfe5df15330d
posterior_samples = DataFrame(chain)

# â•”â•â•¡ fbe04777-fe1c-4f75-8059-80abd2da17da
md"for initial guesses for chain starts when computing info gain"

# â•”â•â•¡ 52dc4eb7-702c-4c1f-967d-34c431b74436
function grab_posterior_sample(posterior_samples::DataFrame, params::Vector{Symbol})
	i = sample(1:nrow(posterior_samples))
	return Vector(posterior_samples[i, params])
end

# â•”â•â•¡ 34b9ba4a-5a24-48c1-9cbe-5f4084b501ed
grab_posterior_sample(posterior_samples, params)

# â•”â•â•¡ fdd7373d-47e7-4f17-869f-03b2145c1c02
md"## viz convergence"

# â•”â•â•¡ 14334653-2134-4782-a2d9-ef84837b2c45
function draw_convergence_diagnostics(posterior_samples::DataFrame, param::String)
	n_chains = length(unique(posterior_samples[:, "chain"]))
	
	fig = Figure()
	
	# axes
	ax = Axis(fig[1, 1], xlabel="iteration", ylabel=param)
	ax_d = Axis(fig[1, 2], xlabel="density")

	# axes stuff
	linkyaxes!(ax, ax_d)
	colsize!(fig.layout, 2, Relative(0.2))
	hideydecorations!(ax_d, grid=false)

	# loop over chains
	for data in groupby(posterior_samples, :chain)
		c = data[1, :chain]
		
		# caterpillar
		lines!(ax, data[:, param], linewidth=1, label="chain $c", color=colors[c])

		# histogram
		density!(
			ax_d, data[:, param], color=colors[c], direction=:y, alpha=0.5,
			strokecolor=colors[c], strokewidth=1
		)
	end
	axislegend(ax)
	
	fig
end

# â•”â•â•¡ 6c255255-f3b4-4112-b06b-7583781eb69e
draw_convergence_diagnostics(posterior_samples, "câ˜…")

# â•”â•â•¡ c9f08ffb-b44f-4be3-881d-096020f17493
md"## viz posterior distn"

# â•”â•â•¡ 06cf608e-782e-4c67-acb2-3aead3642704
function viz(
	data::DataFrame, posterior_samples::DataFrame;
	Î±s::Union{Vector{Float64}, Nothing}=nothing
)
	cs = range(0.0, c_max, length=100)
	
	fig = Figure(size=(500, isnothing(Î±s) ? 500 : 700))
	ax = Axis(
		fig[1, 1], xlabel="[surfactant] (mol/mÂ³)", ylabel="surface tension (N/m)"
	)
	ax_t = Axis(
		fig[0, 1], ylabel="posterior\ndensity\nof câ˜…", title=expt
	)
	
	linkxaxes!(ax, ax_t)
	rowsize!(fig.layout, 1, Relative(isnothing(Î±s) ? 0.8 : 0.7))
	
	# posterior over câ˜…
	density!(ax_t, posterior_samples[:, "câ˜…"], color=colors[3])

	# posterior surface tension vs. surfactant conc. samples
	for s = 1:25
		i = sample(1:nrow(posterior_samples))
		a, K, câ˜… = posterior_samples[i, ["a", "K", "câ˜…"]]
				
		lines!(
			ax, cs, Î³_model.(cs, Î³â‚€, a, K, câ˜…), 
			color=(colors[2], 0.1), label="posterior sample")
	end
	
	# data
	scatter!(
		ax, data[:, "[S] (mol/mÂ³)"], data[:, "Î³ (N/m)"], label="data",
		color=colors[1]
	)

	# credible interval
	lo, hi = quantile(posterior_samples[:, "câ˜…"], [0.1, 0.9])
	ci_string = "80%" * @sprintf(" CI for câ˜…:\n[%.2f, %.2f] mol/mÂ³", lo, hi)
	
	hidexdecorations!(ax_t, grid=false)
	axislegend(ax, ci_string, unique=true, titlefont=:regular)

	if ! isnothing(Î±s)
		ax_b = Axis(
			fig[2, 1], ylabel="information\ngain", xlabel="[surfactant] (mmol/mÂ³)"
		)
		hidexdecorations!(ax, grid=false)
		linkxaxes!(ax_b, ax_t, ax)
		scatterlines!(range(0.0, c_max, length=length(Î±s)), Î±s, color=colors[4])
	end
	xlims!(0, c_max)
	if ! subsample_the_data
		save(expt * "_fit.pdf", fig)
	else
		save(expt * "_w_info_gain2.pdf", fig)
	end
	fig
end

# â•”â•â•¡ e6ea645f-282c-4598-8755-be568d7b3d2e
viz(data, posterior_samples)

# â•”â•â•¡ 49199459-f93c-4a23-8bed-1ea6b2fa2c94
md"# entropy

computing the entropy of a distribution from samples.

ğŸ’¡ integrate a kernel density estimate of the pdf.
"

# â•”â•â•¡ 192b5353-c0d5-457a-bf59-579709d8f2ec
function entropy(xs::Vector{Float64})
	# integration bounds
	xmin = minimum(xs) - std(xs)
	xmax = maximum(xs) + std(xs)

	# kernel density estimation
	the_kde = kde(xs)
	Ï = x -> pdf(the_kde, x)

	# integrate density to get entropy
	function S_integrand(x)
		the_Ï = Ï(x)
		if the_Ï > 0.0
			return - the_Ï * log(the_Ï)
		else
			return 0.0
		end
	end
	
	S = hquadrature(S_integrand, xmin, xmax, reltol=1e-4, maxevals=250)[1]

	return S
end

# â•”â•â•¡ 085d09d1-375f-4d97-92c1-73161383c0cf
begin
	# test with entropy of a Gaussian
	local Ïƒ = 2.0
	local HÌƒ = entropy(Ïƒ * randn(100000))
	local H = 1/2 * (1 + log(2 * Ï€ * Ïƒ ^ 2))
	@test isapprox(H, HÌƒ, atol=0.01)
end

# â•”â•â•¡ aeaac1d5-d5f4-4993-ae95-e8b9a5c82e77
md"entropy of câ˜… over the multiple chains"

# â•”â•â•¡ fa9012a4-24f4-4358-92b3-74cb37270d31
[entropy(Vector(chain[:câ˜…][:, c])) for c = 1:n_chains]

# â•”â•â•¡ 64ebafed-7692-4fa1-bbed-fc2cde90af6b
md"# acquisition"

# â•”â•â•¡ f1ec7091-d47e-475d-885a-fcc96ceab663
function Î±_ig(
	c, data::DataFrame, posterior_samples::DataFrame; 
	n_samples::Int=100, n_MC_samples::Int=100
)
	Logging.disable_logging(Logging.Info)  # Disables info-level messages
	S_news = zeros(n_samples)
	for s = 1:n_samples
		#=
		sample from posterior
		=#
		i = sample(1:nrow(posterior_samples))
		a, K, câ˜… = posterior_samples[i, ["a", "K", "câ˜…"]]
	
		#=
		fantasize a measurement at this c
		=#
		Î³_obs = Î³_model(c, Î³â‚€, a, K, câ˜…) + randn() * Ïƒ
	
		# augment data with fantasized data
		new_data = deepcopy(data)
		push!(new_data, Dict("[S] (mol/mÂ³)" => c, "Î³ (N/m)" => Î³_obs))
	
		#=
		update posterior with fantasized data point
		=#
		new_model = cmc_model(new_data)
		initial_params = [
			grab_posterior_sample(posterior_samples, params) for c = 1:n_chains
		]
		new_chain = DataFrame(
			sample(
				new_model, NUTS(), MCMCThreads(), 
				round(Int, n_MC_samples / n_chains), n_chains, 
				progress=false,
				initial_params=initial_params
			)
		)

		#=
		compute entropy of câ˜… in new posterior
		=#
		S_news[s] = entropy(new_chain[:, "câ˜…"])
	end
	
	#=
	compute current and average of new entropies of câ˜…
	=#
	S_now = entropy(posterior_samples[:, "câ˜…"])
	ğ”¼_S_next = mean(S_news)
	
	Logging.disable_logging(Logging.BelowMinLevel) # don't wanna disable logging
	
	return S_now - ğ”¼_S_next
end

# â•”â•â•¡ e759e6f4-3366-4d94-93fc-1f6f5cb59e2b
md"time a single run"

# â•”â•â•¡ fc333a63-86f1-43d6-9f7e-1f43bd926caf
@time Î±_ig(1.0, data, posterior_samples, n_samples=200, n_MC_samples=50)

# â•”â•â•¡ 1b92732c-e918-41d1-b422-822794f850e5
md"
ğŸ§ª check if the estimate of the information gradient via sampling is consisistent over multiple runs, so we can assess if we have a sufficient number of samples? check here. ğŸ‘‡

$(@bind check_sampling CheckBox(default=false))"

# â•”â•â•¡ 48e51f57-3d7e-4096-b5c2-67a2244ba2e9
if check_sampling
	[Î±_ig(1.0, data, posterior_samples, n_samples=200, n_MC_samples=50) for i = 1:4]
end

# â•”â•â•¡ 3dd13aca-090d-4ba4-8086-85c56f7d0065
md"
ğŸ”¨ actually compute the information gradient acquisition function at each next surface concentration? check here. ğŸ‘‡

$(@bind compute_Î± CheckBox(default=false))"

# â•”â•â•¡ ed12167e-0ee3-472c-93d5-3424453019c4
begin
	cs = collect(range(0.0, c_max, length=50))
	Î±s = zeros(length(cs))
	if compute_Î±
		@progress for i = 1:length(cs)
			Î±s[i] = Î±_ig(
				cs[i], data, posterior_samples, 
				n_samples=250, n_MC_samples=50
			)
		end
	end
end

# â•”â•â•¡ e42e86a9-8b9a-432a-8c5a-f463d97ce1f2
if compute_Î±
	viz(data, posterior_samples, Î±s=Î±s)
end

# â•”â•â•¡ Cell order:
# â• â•cd47d8d0-5513-11f0-02cf-23409fc28fbf
# â• â•1e324846-70da-494c-bb88-8668a0f0e526
# â• â•0801bc21-de7c-4470-ae89-8725d90812e9
# â• â•4cb87445-d372-4957-9cdb-4cd4bcc397de
# â•Ÿâ”€5a1768a0-865a-46ba-b70f-0194664d9d21
# â• â•d506f9e7-0d4d-40eb-a938-e1465c836222
# â•Ÿâ”€5da8817c-3460-4c04-b408-aff71e4576d4
# â•Ÿâ”€17d43d3c-ad92-4447-adc1-dbd23001c45e
# â• â•8511592a-9059-43a7-b14c-941b66641cb0
# â• â•49de609d-4cc3-46d6-9141-5de0395088fb
# â•Ÿâ”€842d16b1-26e3-4cd2-81ac-83ed6cd3b6b3
# â• â•533a51d0-3b42-42e0-b8db-1ab7c672f3df
# â•Ÿâ”€874cc30e-0d7d-4a82-a523-c0caa9da4a59
# â• â•b686a78a-fba7-41f5-b30f-621e3416ae96
# â•Ÿâ”€ca288f74-bc34-457f-8caa-ab1627f5c46f
# â•Ÿâ”€c40e781e-bd35-4541-9eb3-f943df41587d
# â• â•67d23697-2d05-46f2-80e4-75c85c369f80
# â•Ÿâ”€9b865570-b175-4fcb-a835-b8d6278c86ac
# â• â•17ab88fc-8d65-42a8-94a7-3ac643638ef7
# â• â•bcd013f5-3211-4ca4-ac1d-fae758199e75
# â• â•9d2f66ee-03aa-42d9-ae9d-6ee14f1f1f63
# â•Ÿâ”€f0b122c9-4d43-405b-a28e-ead0c79772cb
# â• â•ea27c7f7-0073-4d0b-a171-7b404af1d0d6
# â• â•948a0fe4-e8ec-47e5-92a7-a66be020f0df
# â• â•a4f779ba-9410-4e67-840f-7114561f23b4
# â•Ÿâ”€37dc8c68-2270-4226-b209-f3fab65b3b13
# â• â•52080b61-1e8d-4343-b79c-b3b39861e2c8
# â• â•bfa76e5b-e2c3-449b-8de0-cfe5df15330d
# â•Ÿâ”€fbe04777-fe1c-4f75-8059-80abd2da17da
# â• â•52dc4eb7-702c-4c1f-967d-34c431b74436
# â• â•34b9ba4a-5a24-48c1-9cbe-5f4084b501ed
# â•Ÿâ”€fdd7373d-47e7-4f17-869f-03b2145c1c02
# â• â•14334653-2134-4782-a2d9-ef84837b2c45
# â• â•6c255255-f3b4-4112-b06b-7583781eb69e
# â•Ÿâ”€c9f08ffb-b44f-4be3-881d-096020f17493
# â• â•06cf608e-782e-4c67-acb2-3aead3642704
# â• â•e6ea645f-282c-4598-8755-be568d7b3d2e
# â•Ÿâ”€49199459-f93c-4a23-8bed-1ea6b2fa2c94
# â• â•192b5353-c0d5-457a-bf59-579709d8f2ec
# â• â•085d09d1-375f-4d97-92c1-73161383c0cf
# â•Ÿâ”€aeaac1d5-d5f4-4993-ae95-e8b9a5c82e77
# â• â•fa9012a4-24f4-4358-92b3-74cb37270d31
# â•Ÿâ”€64ebafed-7692-4fa1-bbed-fc2cde90af6b
# â• â•f1ec7091-d47e-475d-885a-fcc96ceab663
# â•Ÿâ”€e759e6f4-3366-4d94-93fc-1f6f5cb59e2b
# â• â•fc333a63-86f1-43d6-9f7e-1f43bd926caf
# â•Ÿâ”€1b92732c-e918-41d1-b422-822794f850e5
# â• â•48e51f57-3d7e-4096-b5c2-67a2244ba2e9
# â•Ÿâ”€3dd13aca-090d-4ba4-8086-85c56f7d0065
# â• â•ed12167e-0ee3-472c-93d5-3424453019c4
# â• â•e42e86a9-8b9a-432a-8c5a-f463d97ce1f2
